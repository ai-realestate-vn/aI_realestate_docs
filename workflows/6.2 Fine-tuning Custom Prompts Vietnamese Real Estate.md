# Workflow 6.2 â€“ Fineâ€‘tuning & Custom Prompts (Vietnamese Real Estate)

> **Má»¥c tiÃªu:** Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c, giá»ng Ä‘iá»‡u nháº¥t quÃ¡n, giáº£m áº£o tÆ°á»Ÿng vÃ  chi phÃ­ suy luáº­n. TÆ°Æ¡ng thÃ­ch 1.x (NLU/DM/NLG), 5.x (Auth/Privacy/Retention) vÃ  6.1 (RAG/Vector DB).

---

## ğŸ¯ Má»¥c tiÃªu & Pháº¡m vi

**Custom Prompts:** thiáº¿t káº¿ há»‡ thá»‘ng prompt (system/instruction, planner, toolâ€‘use, guardrail) + fewâ€‘shot chuáº©n hoÃ¡.

**Fineâ€‘tuning (PEFT/LoRA/QLoRA):** tinh chá»‰nh cho nhiá»‡m vá»¥ háº¹p (clarify slot, tráº£ lá»i cÃ³ trÃ­ch dáº«n nguá»“n, booking flow).

**KhÃ´ng má»¥c tiÃªu:** â€œtá»± há»c onlineâ€ táº¡i runtime. LuÃ´n theo chu ká»³ **train â†’ eval â†’ canary â†’ A/B**.

---

## ğŸ§± Lá»±a chá»n chiáº¿n lÆ°á»£c

- **Chá»‰ Prompting** khi: miá»n háº¹p, dá»¯ liá»‡u vÃ ng Ã­t (< 2k cáº·p), yÃªu cáº§u cáº­p nháº­t nhanh.
- **PEFT/QLoRA** khi: cáº§n hÃ nh vi nháº¥t quÃ¡n, giáº£m token Ä‘áº§u ra, xá»­ lÃ½ tiáº¿ng Viá»‡t dÃ i, hoáº·c toolâ€‘use máº«u hoÃ¡.
- **RAG + Prompting (khuyáº¿n nghá»‹ ná»n táº£ng):** má»i cÃ¢u tráº£ lá»i Ä‘á»u pháº£i dá»±a nguá»“n (6.1).

---

## ğŸ—ƒï¸ Chuáº©n dá»¯ liá»‡u (Instruction/Chat Format)

**Schema tá»‘i thiá»ƒu (JSONL)**

```json
{"instruction":"Táº¡o cÃ¢u há»i lÃ m rÃµ thiáº¿u slot","input":"User: CÄƒn 2PN Q7\nSlots thiáº¿u: dien_tich","output":"Äá»ƒ lá»c chÃ­nh xÃ¡c hÆ¡n, anh/chá»‹ cho em biáº¿t diá»‡n tÃ­ch tá»‘i thiá»ƒu (vÃ­ dá»¥ 65 mÂ²) áº¡?"}
{"messages":[
  {"role":"system","content":"Báº¡n lÃ  trá»£ lÃ½ BÄS Viá»‡t Nam..."},
  {"role":"user","content":"Theo Luáº­t NhÃ  á»Ÿ 2014, Ä‘iá»u kiá»‡n cáº¥p sá»• há»“ng chung cÆ°?"},
  {"role":"assistant","content":"Theo Äiá»u ... [Nguá»“n: ...]"}
]}
```

**Tag meta** (lá»c/Ä‘Ã¡nh giÃ¡):

- `domain`: `real_estate` | `learning`
- `task`: `clarify` | `result_list` | `law_grounded` | `booking_confirm`
- `tone`: `polite-pro` | `neutral`
- `language`: `vi-VN`

---

## ğŸ§© Thiáº¿t káº¿ Prompt Stack

### 1) System (báº¥t biáº¿n, ngáº¯n, rÃ ng buá»™c)
- Vai trÃ²: Trá»£ lÃ½ BÄS Viá»‡t Nam, **lá»‹ch sá»± â€“ ngáº¯n gá»n â€“ tá»± nhiÃªn**.
- **KhÃ´ng bá»‹a**; luÃ´n trÃ­ch dáº«n nguá»“n khi dá»±a tÃ i liá»‡u (6.1).
- KhÃ´ng cam káº¿t phÃ¡p lÃ½/lá»£i nhuáº­n; tÃ´n trá»ng 5.1â€“5.3 (mask PII, privacy/retention).

### 2) Planner (áº©n / toolâ€‘use)
- Náº¿u `intent=tim_bds` & thiáº¿u slot â†’ **sinh 1 cÃ¢u clarify** (< 20 tá»«).
- Náº¿u cÃ³ káº¿t quáº£ â†’ **tÃ³m táº¯t 1 cÃ¢u + 3 bullet + CTA**.
- Náº¿u RAG khÃ´ng Ä‘á»§ â†’ **xin phÃ©p há»i láº¡i** hoáº·c **tá»« chá»‘i lá»‹ch sá»±**.

### 3) Fewâ€‘shot theo act
- 3â€“6 vÃ­ dá»¥/act (clarify, booking confirm, noâ€‘result, law grounded).

### 4) Output Schema Guard
- YÃªu cáº§u **JSON há»£p lá»‡** khi FE/BE cáº§n (messages/cards/quick_replies).
- KÃ¨m **functionâ€‘call schema** náº¿u dÃ¹ng tool API.

---

## ğŸ”§ Fineâ€‘tuning (PEFT/QLoRA) â€“ Quy trÃ¬nh

### 1) Chá»n model ná»n
- Nháº¹, tiáº¿ng Viá»‡t tá»‘t: **Qwen 1.5/2 (1.8Bâ€“7B)**, **Llamaâ€‘3â€‘Instruct 8B**, **Gemmaâ€‘2 9B**.
- Háº¡ táº§ng VRAM háº¡n cháº¿: **QLoRA 4â€‘bit** + gradient checkpointing (**Unsloth** há»— trá»£ tá»‘t).

### 2) Chuáº©n dá»¯ liá»‡u FT
- Gom dialogs vÃ ng tá»« 1.5 (Learning): *lowâ€‘conf, fail* â†’ chuáº©n hoÃ¡.
- **áº¨n PII (5.2)**; loáº¡i turn nháº¡y cáº£m. Balance theo task/domain.
- Tá»‘i thiá»ƒu **5â€“10k máº«u** Ä‘a dáº¡ng (hÃ nh vi cá»‘t lÃµi); cÃ³ thá»ƒ báº¯t Ä‘áº§u **1â€“2k** (PEFT).

### 3) Huáº¥n luyá»‡n (vÃ­ dá»¥ **Unsloth + TRL**)
- Má»¥c tiÃªu: **giáº£m Ä‘á»™ dÃ i pháº£n há»“i**, **giá»¯ schema**, **cáº£i thiá»‡n Vietnamese fluency**.
- Loss: SFT tiÃªu chuáº©n; tuá»³ chá»n **constraint loss** pháº¡t ngoÃ i schema.
- **Config gá»£i Ã½** (QLoRA, 7B, 1Ã—24GB):
  - `bnb_4bit=True`, `r=16â€“32`, `lora_alpha=32â€“64`, `lora_dropout=0.05`
  - `lr=1e-4 ~ 2e-4`, `bsz_eff=64` (grad accumulation), `epochs=2â€“3`
  - `target_modules`: attention proj + MLP up/down (tuá»³ model)
  - `max_seq_len=2k`; **packing** náº¿u phÃ¢n phá»‘i Ä‘á»™ dÃ i khÃ´ng Ä‘á»u

```python
from unsloth import FastLanguageModel
from trl import SFTTrainer
from transformers import TrainingArguments

model, tok = FastLanguageModel.from_pretrained(
  "Qwen/Qwen2-7B-Instruct", load_in_4bit=True, max_seq_length=2048
)
model = FastLanguageModel.get_peft_model(
  model, r=32, target_modules=["q_proj","v_proj","k_proj","o_proj","gate_proj","up_proj","down_proj"],
  lora_alpha=64, lora_dropout=0.05, bias="none", task_type="CAUSAL_LM"
)

args = TrainingArguments(
  output_dir="ft-qwen2-7b-r32",
  learning_rate=2e-4, num_train_epochs=2,
  per_device_train_batch_size=2, gradient_accumulation_steps=32,
  logging_steps=20, save_steps=500, bf16=True, lr_scheduler_type="cosine",
  warmup_ratio=0.05
)

trainer = SFTTrainer(
  model=model, train_dataset=train_ds, dataset_text_field="text",
  max_seq_length=2048, tokenizer=tok, args=args, packing=True
)
trainer.train(); model.save_pretrained("artifacts/lora")
```

### 4) ÄÃ¡nh giÃ¡
- **Offline:** exactâ€‘match **schema JSON**; *BLEU/ROUGE* < *Task Success* (clarify Ä‘Ãºng slot, cÃ³ trÃ­ch dáº«n).
- **Constitutional tests:** â€œnoâ€‘source â†’ tá»« chá»‘iâ€; â€œpolicy claim â†’ hedgeâ€.
- **Regression:** bá»™ 200â€“300 há»™i thoáº¡i chuáº©n vÃ ng.

### 5) Triá»ƒn khai
- **Mergeâ€‘weights** (optional) hoáº·c **attach LoRA** khi suy luáº­n.
- Tag phiÃªn báº£n: `llm-base@ver + lora@ver + prompt@ver`.
- **Canary 5â€“10%**; rollback náº¿u *hallucinationâ†‘* hoáº·c *schema errorâ†‘*.

---

## ğŸ›¡ï¸ Guardrails & An toÃ n
- Prompt rule: **khÃ´ng bá»‹a nguá»“n**, luÃ´n â€œTheo [Nguá»“n: â€¦]â€.
- **Max tokens** + phong cÃ¡ch â€œshortâ€‘answerâ€ Ä‘á»ƒ trÃ¡nh lan man.
- **Safety checker** (rule & LLMâ€‘critic): phÃ¡p lÃ½/Ä‘áº§u tÆ°, PII, cam káº¿t giÃ¡.
- **Schema validator** trÆ°á»›c khi tráº£ vá» FE (sai â†’ autoâ€‘repair hoáº·c fallback template).

---

## ğŸ§ª Bá»™ prompt máº«u (rÃºt gá»n, viâ€‘VN)

### System
> Báº¡n lÃ  Trá»£ lÃ½ BÄS Viá»‡t Nam. LuÃ´n: 1) Ngáº¯n gá»n, lá»‹ch sá»±, tá»± nhiÃªn. 2) Dá»±a nguá»“n (6.1). Náº¿u thiáº¿u nguá»“n: xin phÃ©p há»i thÃªm hoáº·c tá»« chá»‘i. 3) KhÃ´ng kháº³ng Ä‘á»‹nh phÃ¡p lÃ½/lá»£i nhuáº­n; dÃ¹ng â€œTheo [Nguá»“n:â€¦]â€. 4) Khi Ä‘Æ°á»£c yÃªu cáº§u UI, tráº£ **JSON** Ä‘Ãºng schema.

### Planner â€“ Clarify
**Nhiá»‡m vá»¥:** Náº¿u thiáº¿u slot `{slot_list}`, hÃ£y há»i **Ä‘Ãºng 1 cÃ¢u rÃµ rÃ ng** (< 20 tá»«), khÃ´ng gá»£i Ã½ dÆ°.  
**Ngá»¯ cáº£nh:** `{context_summary}`  
**Äáº§u ra:** chá»‰ **cÃ¢u há»i** lÃ m rÃµ.

### Answer w/ citations
- **CÃ¢u há»i:** `{query_norm}`
- **Ngá»¯ cáº£nh (â‰¤ 3 Ä‘oáº¡n):** `{ctx_1}\n{ctx_2}\n{ctx_3}`
- **YÃªu cáº§u:** tráº£ lá»i â‰¤ 3 cÃ¢u, cuá»‘i cÃ¹ng chÃ¨n: `[Nguá»“n: {doc_id}:{section} ({date})]`.  
Náº¿u khÃ´ng Ä‘á»§ ngá»¯ cáº£nh: nÃ³i *"ChÆ°a Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ káº¿t luáº­n."* vÃ  gá»£i Ã½ **1 cÃ¢u há»i lÃ m rÃµ**.

### JSON UI (cards)
**Tráº£ vá» Ä‘Ãºng schema**:

```json
{"messages":[{"type":"text","content":""}],"cards":[],"quick_replies":[]}
```

> **Chá»‰ JSON, khÃ´ng thÃªm chá»¯ thÆ°á»ng.**

---

## ğŸ“ˆ Chá»‰ sá»‘ & A/B

- **Task Success** (Ä‘áº·t lá»‹ch/ má»Ÿ chi tiáº¿t/ cÃ¢u lÃ m rÃµ Ä‘Ãºng): â†‘ so baseline â‰¥ **+5â€“10%**
- **Hallucination Rate** (khÃ´ng nguá»“n/nguá»“n sai): **< 1â€“2%**
- **Schema Error Rate** (JSON invalid): **< 0.5%**
- **Avg Tokens Out:** giáº£m **â‰¥ 15%** (sau FT/prompt tuning)
- **Latency p95:** khÃ´ng tÄƒng > **10%** so baseline

---

## ğŸ”Œ TÃ­ch há»£p vá»›i 6.1 & 1.x, 5.x

- **6.1** cáº¥p context + citation â†’ dÃ¹ng prompt **Answer w/ citations**.
- **1.3 (Policy)** chá»n act: Clarify vs Result List â†’ chá»n prompt/act tÆ°Æ¡ng á»©ng.
- **5.1** Ã¡p AuthZ filter trÆ°á»›c khi RAG; **5.2** che PII trong prompt; **5.3** kiá»ƒm soÃ¡t retention.

---

## âœ… Checklist MVP (1â€“2 tuáº§n)

- **Prompt stack** (system/planner/acts) + **20â€“40 fewâ€‘shot** chuáº©n vÃ ng.
- **Dataset SFT 2â€“5k** cáº·p (clarify, lawâ€‘grounded, result_list, booking_confirm).
- **Train QLoRA (7B)** + **eval offline** + **regression 200** há»™i thoáº¡i.
- **Inference attachâ€‘LoRA** + **schema validator** + **canary 10%**.
- **Dashboard:** Task Success, Hallucination, Schema Error, Tokens Out, Latency.
- **Playbook rollback** & **promptâ€‘hotfix** (khÃ´ng cáº§n retrain khi lá»‡ch vÄƒn phong).

